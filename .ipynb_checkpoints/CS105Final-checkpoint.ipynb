{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS105 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Meet and greet the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load in data\n",
    "- Call function parse(path)\n",
    "- Call funcation getDF(path)\n",
    "- Return the dataframe in its correct form\n",
    "- A dataset should be split into two forms\n",
    "    - One will contain our main dataframe which will not be touched unless for comparisons with our modified df\n",
    "    - The second will contain our changed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse(path):\n",
    "  \"\"\" This function will parse the json file and returns the memory of all the rows\n",
    "\n",
    "  Args:\n",
    "      path (string): path directory of where your data is saved on your computer\n",
    "\n",
    "  Yields:\n",
    "      object: json\n",
    "  \"\"\"\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(path):\n",
    "    \"\"\" This function will go through each row in the parse function and get the data into a pandas format\n",
    "\n",
    "    Args:\n",
    "        path (string): path directory of where your data is saved on your computer\n",
    "\n",
    "    Returns:\n",
    "       dataframe: main dataframe that holds our data\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = getDF(r'C:\\Users\\migue\\Downloads\\Cell_Phones_and_Accessories_5.json.gz')\n",
    "# data_copy = getDF(r'C:\\Users\\migue\\Downloads\\Cell_Phones_and_Accessories_5.json.gz')\n",
    "\n",
    "df = getDF('Cell_Phones_and_Accessories_5.json.gz')\n",
    "data_copy = getDF('Cell_Phones_and_Accessories_5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get familiar with the data \n",
    "- Get info from dataframe\n",
    "- Get a random sample\n",
    "- Check the length of the df\n",
    "- Check dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1128437 entries, 0 to 1128436\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   overall         1128437 non-null  float64\n",
      " 1   verified        1128437 non-null  bool   \n",
      " 2   reviewTime      1128437 non-null  object \n",
      " 3   reviewerID      1128437 non-null  object \n",
      " 4   asin            1128437 non-null  object \n",
      " 5   style           605241 non-null   object \n",
      " 6   reviewerName    1128302 non-null  object \n",
      " 7   reviewText      1127672 non-null  object \n",
      " 8   summary         1127920 non-null  object \n",
      " 9   unixReviewTime  1128437 non-null  int64  \n",
      " 10  vote            92034 non-null    object \n",
      " 11  image           27107 non-null    object \n",
      "dtypes: bool(1), float64(1), int64(1), object(9)\n",
      "memory usage: 104.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_copy.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_copy.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total length of the dataset:  1128437\n"
     ]
    }
   ],
   "source": [
    "print(\"The total length of the dataset: \", len(data_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data types of each respective column: \n",
      "overall           float64\n",
      "verified             bool\n",
      "reviewTime         object\n",
      "reviewerID         object\n",
      "asin               object\n",
      "style              object\n",
      "reviewerName       object\n",
      "reviewText         object\n",
      "summary            object\n",
      "unixReviewTime      int64\n",
      "vote               object\n",
      "image              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"The data types of each respective column: \")\n",
    "print(data_copy.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 The 4 C's of data cleaning: correction, completing, creating, and converting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Completing \n",
    "- Completing missing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                 0\n",
       "verified                0\n",
       "reviewTime              0\n",
       "reviewerID              0\n",
       "asin                    0\n",
       "style              523196\n",
       "reviewerName          135\n",
       "reviewText            765\n",
       "summary               517\n",
       "unixReviewTime          0\n",
       "vote              1036403\n",
       "image             1101330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_ocols(df, nan_percent=0.7):\n",
    "    \"\"\" This function will determine what columns to drop based on our threshold\n",
    "\n",
    "    Args:\n",
    "        df (pandas df): dataframe that holds our data\n",
    "        nan_percent (float, optional): Defaults to 0.7.\n",
    "\n",
    "    Returns:\n",
    "        list: list of columns to drop based on our threshold\n",
    "    \"\"\"\n",
    "    threshold = len(df.index) * nan_percent\n",
    "    return [c for c in df.columns if df[c].isnull().sum() >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_del = get_nan_ocols(data_copy, .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vote', 'image']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data_copy.drop(['vote', 'image'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_copy.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Correction\n",
    "- Correcting values and outliers\n",
    "     - We could have possible outliers in any of the numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Converting \n",
    "- Converting fields to the correct format for calculations and presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feature engineering\n",
    "- Creating new features for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTextArray = []\n",
    "individualTextArray = []\n",
    "#loop through text and append words to textArray\n",
    "#remove \"useless\" words by comparing them to a \"useless\" word collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 If predictions suck, hyperparameter tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Repeat steps 4-7 until satisfied"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9762498ba689a3e02831ca2efc3750b8f05cb0af915b6ebb42c687bd5ecab58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
